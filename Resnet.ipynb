{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Vl4lOhIcdl",
        "colab_type": "code",
        "outputId": "1a91e5bc-6a38-450b-eb3d-f6564a684f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "source": [
        "import torch \n",
        "import numpy as np \n",
        "import torchvision.transforms as transforms \n",
        "import torchvision \n",
        "import torch.nn.functional as F\n",
        "\n",
        "#Define what steps to take in a layer, i.e. convolution and batch norm\n",
        "class Block(torch.nn.Module):\n",
        "  \n",
        "    def __init__(self,input_planes,planes,stride=1,size_change=None):\n",
        "      #size_change is set to none by default and will change if we need to resize matrix before adding to output\n",
        "        super(Block,self).__init__()\n",
        "        #define convolution function\n",
        "        self.conv1 = torch.nn.Conv2d(input_planes,planes,stride=stride,kernel_size=3,padding=1)\n",
        "        self.bn1   = torch.nn.BatchNorm2d(planes)\n",
        "        self.conv2 = torch.nn.Conv2d(planes,planes,stride=1,kernel_size=3,padding=1)\n",
        "        self.bn2   = torch.nn.BatchNorm2d(planes)\n",
        "        #change the depth of input if it has to be added with a tensor of different size\n",
        "        self.size_change = size_change\n",
        "        mn  \n",
        "        \n",
        "    #this function goes throgh a block (two layers) and then returns the output\n",
        "    def forward(self,x):\n",
        "        #Save the residue so it can be added later with output\n",
        "        res = x\n",
        "        #first block : conv -> batch norm -> Relu\n",
        "        output = F.relu(self.bn1(self.conv1(x)))\n",
        "        #second block, we stop after bn to change size if needed and then add the residue(x)\n",
        "        output = self.bn2(self.conv2(output))\n",
        "        \n",
        "        #resize matrix if needed\n",
        "        if self.size_change is not None:\n",
        "            res = self.size_change(res)\n",
        "        #add residue to input (H(x) = f(x) + x)\n",
        "        output += res\n",
        "        #Now do relu on H(x)\n",
        "        output = F.relu(output)\n",
        "\n",
        "        return output\n",
        " \n",
        "\n",
        "class ResNet(torch.nn.Module):\n",
        "  \n",
        "    #we define the structure of resnet here, using function layer which outputs the tensor after operations from a block \n",
        "    def __init__(self,block,classes=10):\n",
        "        super(ResNet,self).__init__()\n",
        "        #defining structure\n",
        "        self.input_planes = 64\n",
        "        #first conv layer\n",
        "        self.conv = torch.nn.Conv2d(3,64,kernel_size=3,stride=1,padding=1)\n",
        "        self.bn   = torch.nn.BatchNorm2d(64)\n",
        "        #define four types of layers\n",
        "        #acc to resnet architecture, layers are repeated 3,4,6,3 time respectively\n",
        "        self.layer1 = self._layer(block,64,3,stride=1)\n",
        "        self.layer2 = self._layer(block,128,4,stride=2)\n",
        "        self.layer3 = self._layer(block,256,6,stride=2) \n",
        "        self.layer4 = self._layer(block,512,3,stride=2)\n",
        "        #average pooling over final output\n",
        "        self.averagePool = torch.nn.AvgPool2d(kernel_size=4,stride=1)\n",
        "        #fully connected layer\n",
        "        self.fc    =  torch.nn.Linear(512,classes)\n",
        "    \n",
        "    def _layer(self,block,planes,num_layers,stride=1):\n",
        "        size_change = None\n",
        "        #conditions when size of tensor needs to be changed\n",
        "        if stride!=1 or planes != self.input_planes:\n",
        "          #we will use 1X1 convolution to resize the matrix and then batch normalize it\n",
        "            size_change = torch.nn.Sequential(torch.nn.Conv2d(self.input_planes,planes,kernel_size=1,stride=stride),\n",
        "                                             torch.nn.BatchNorm2d(planes))\n",
        "        \n",
        "        #layers is a list that contains all the layers in a block. Then we will use this list and create a sequential model\n",
        "        #using pytorch's built in nn.sequential function.\n",
        "        Layers =[]\n",
        "        #if size needs to be changed, we will do it in the first layer by passing the size_change in Steps\n",
        "        Layers.append(block(self.input_planes,planes,stride=stride,size_change=size_change))\n",
        "        self.input_planes = planes\n",
        "        #now we will append the rest of the layers. we start from 1 because we have already created the first layer in resizing above\n",
        "        for i in range(1,num_layers):\n",
        "            Layers.append(block(self.input_planes,planes))\n",
        "            self.input_planes = planes\n",
        "        \n",
        "        #we use torch's built in fucntion to convert list Layers to a pytorch network\n",
        "        return torch.nn.Sequential(*Layers)\n",
        "\n",
        "    def forward(self,x):\n",
        "      #x is the input matrix\n",
        "        x = F.relu(self.bn(self.conv(x)))\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = F.avg_pool2d(x,4)\n",
        "        #convert 3d matrix to 2d\n",
        "        x = x.view(x.size(0),-1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "   \n",
        "  \n",
        "def test():\n",
        "        #to convert image to tensor\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "        )\n",
        "\n",
        "    #Load train and test set:\n",
        "    #load train data\n",
        "    train = torchvision.datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)\n",
        "    #we use SGD with batch size = 256 acc to research paper\n",
        "    trainset = torch.utils.data.DataLoader(train,batch_size=256,shuffle=True)\n",
        "    #load test data\n",
        "    test = torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)\n",
        "    testset = torch.utils.data.DataLoader(test,batch_size=256,shuffle=False)\n",
        "    #use gpu\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  \n",
        "    #create an object of ResNet\n",
        "    net =  ResNet(Block)\n",
        "    net.to(device)\n",
        "    #define cost function\n",
        "    costFunc = torch.nn.CrossEntropyLoss()\n",
        "    #lr = learning rate\n",
        "    lr = 0.1\n",
        "    #define SGD\n",
        "    optimizer =  torch.optim.SGD(net.parameters(),lr,momentum=0.9)\n",
        "    #train for 100 epochs\n",
        "    for epoch in range(100):\n",
        "      #initialize continuous loss to 0\n",
        "        closs = 0\n",
        "        #loop through batches in training data and optimize the parameters\n",
        "        for i,batch in enumerate(trainset,0):\n",
        "            data,output = batch\n",
        "            data,output = data.to(device),output.to(device)#send data to GPU\n",
        "            prediction = net(data) #output tensor from resnet\n",
        "            loss = costFunc(prediction,output) #calculates loss function\n",
        "            closs = loss.item() \n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward() #perform backpropagation\n",
        "            optimizer.step()  #optimize using SGD\n",
        "        #define correct and total hits to calculate accuracy on test data\n",
        "        correctHits=0\n",
        "        total=0\n",
        "        #test accuracy on test batch\n",
        "        for batches in testset:\n",
        "            data,output = batches\n",
        "            data,output = data.to(device),output.to(device)\n",
        "            prediction = net(data)\n",
        "            _,prediction = torch.max(prediction.data,1)  #returns max as well as its index\n",
        "            total += output.size(0)\n",
        "            correctHits += (prediction==output).sum().item()\n",
        "        print('Accuracy on epoch ',epoch+1,'= ',str((correctHits/total)*100))\n",
        "    \n",
        "if __name__ == '__main__':\n",
        "    test()\n",
        "  \n",
        "   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Accuracy on epoch  1 =  53.73\n",
            "Accuracy on epoch  2 =  68.41000000000001\n",
            "Accuracy on epoch  3 =  75.83\n",
            "Accuracy on epoch  4 =  78.72\n",
            "Accuracy on epoch  5 =  81.15\n",
            "Accuracy on epoch  6 =  82.03\n",
            "Accuracy on epoch  7 =  82.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbe7xywXP1w_",
        "colab_type": "text"
      },
      "source": [
        "**Explanation of research paper**\n",
        "\n",
        "1. We saw that just stacking more layers is not helpful due to problem of degradation\n",
        "2. Degradation: with increase in layers, accuracy gets saturated and then starts decreasing.\n",
        "3. Degradation is not due to overfitting as training error also increases with increased number of layers.\n",
        "4. Theoretically, if we take a shallow network and add identity layers in between, then we see that the accuracy of this deeper network should not be no less than the shallower network.\n",
        "5. To address the problem of degradation, we create a residual network.\n",
        "6. We assume that it is easier to optimize a function f(x) = 0 by a stack of layers than to optimize an identity function h(x) = x.\n",
        "7. Hence, we write output function h(x) = f(x) + x and call f(x) the residual function.\n",
        "8. In ResNet, layers in the network calculate f(x) and then add the original input x to it to get the final output function h(x)\n",
        "9. Shortcut connections: a connection in the network skipping a few layers and adding the original input x to the output of next few layers f(x).\n",
        "10. Shortcut functions are identity functions and hence introduce no new parameters and add no computational complexity.\n",
        "11. We finally observe through examples of CIFAR-10, ImageNet that ResNet is easier to optiimize than plain networks and has low training error. Also its accuracy can easily be increased by deepening the network.\n",
        "12. When size of output does not match with x from shortcut connections, we use 1X1 convolusion to resize the depth of x.\n",
        "\n",
        "**Implementation**\n",
        "1. Block Class\n",
        "  1. It represents a block in the resnet architecture.\n",
        "  2. It takes an input matrix, does a 3x3 convolution with given stride, performs batch normalization on the matrix, activates it with relu,again does a 3x3 convolution and then batch norm, if size needs to be changed then it resizes input matrix 'x' and then adds output and x and performs relu function and returns the final output.\n",
        "  \n",
        "2. ResNet class:\n",
        "\t1.It contains the architecture of ResNet.\n",
        "\t2.It has layer function to stack together similar blocks.\n",
        "\t3.If input matrix needs to be resized, it will resize the matrix in the first block and then loops over rest of layers.\n",
        "\t4.These layers are stored in a list named Layers, and then converted to a fully connected pytorch network using torch.nn.Sequential() function. \n",
        "\t5.There are 4 different types of layers in resnet, with depths 64, 128 256 and 512 respectively.\n",
        "\t6.We use ResNet-34 architecture from the research paper so layers are repeated 3,4,6,3 times respectively.\n",
        "  7.We then do average pooling and created a fully connected layer to be used by loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUqgn_Cz4AOP",
        "colab_type": "code",
        "outputId": "98b45f6a-a0fd-4bd3-804b-919e4fa7bb29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        }
      },
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "!pip3 install torchvision\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.3.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl (592.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 592.3MB 31.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.14.6)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 1.0.45 has requirement torch>=1.0.0, but you'll have torch 0.3.0.post4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.0.1.post2\n",
            "    Uninstalling torch-1.0.1.post2:\n",
            "      Successfully uninstalled torch-1.0.1.post2\n",
            "Successfully installed torch-0.3.0.post4\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.3.0.post4)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 11.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchvision) (3.13)\n",
            "\u001b[31mimgaug 0.2.8 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 1.0.45 has requirement torch>=1.0.0, but you'll have torch 0.3.0.post4 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u77h8c9h6qqZ",
        "colab_type": "code",
        "outputId": "efa70ccb-0436-4543-9b06-80a4373e3bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmPah2o_6xEu",
        "colab_type": "code",
        "outputId": "c9364698-1508-4b07-b678-b6eaf3df7b27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.0.1.post2 from https://download.pytorch.org/whl/cu100/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl (636.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 636.8MB 25kB/s \n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 0.3.0.post4\n",
            "    Uninstalling torch-0.3.0.post4:\n",
            "      Successfully uninstalled torch-0.3.0.post4\n",
            "Successfully installed torch-1.0.1.post2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.1.post2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}